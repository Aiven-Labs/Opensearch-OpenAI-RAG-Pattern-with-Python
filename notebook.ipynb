{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic search using OpenSearch and OpenAI\n",
    "\n",
    "This notebook guides you through an example of using [Aiven for OpenSearch](https://go.aiven.io/openai-opensearch-os) as a backend vector database for OpenAI embeddings and how to perform semantic search.\n",
    "\n",
    "\n",
    "## Why using OpenSearch as backend vector database\n",
    "\n",
    "OpenSearch is a widely adopted open source search/analytics engine. It allows to store, query and transform documents in a variety of shapes and provides fast and scalable functionalities to perform both accurate and [fuzzy text search](https://opensearch.org/docs/latest/query-dsl/term/fuzzy/). Using OpenSearch as vector database enables you to mix and match semantic and text search queries on top of a performant and scalable engine.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before you begin, ensure to follow the prerequisites:\n",
    "\n",
    "1. An [Aiven Account](https://go.aiven.io/openai-opensearch-signup). You can create an account and start a free trial with Aiven by navigating to the [signup page](https://go.aiven.io/openai-opensearch-signup) and creating a user.\n",
    "2. An [Aiven for OpenSearch service](https://go.aiven.io/openai-opensearch-os). You can spin up an Aiven for OpenSearch service in minutes in the [Aiven Console](https://go.aiven.io/openai-opensearch-console) with the following steps \n",
    "    * Click on **Create service**\n",
    "    * Select **OpenSearch**\n",
    "    * Choose the **Cloud Provider and Region**\n",
    "    * Select the **Service plan** (the `hobbyist` plan is enough for the notebook)\n",
    "    * Provide the **Service name**\n",
    "    * Click on **Create service**\n",
    "3. The OpenSearch **Connection String**. The connection string is visible as **Service URI** in the Aiven for OpenSearch service overview page.\n",
    "4. Your [OpenAI API key](https://platform.openai.com/account/api-keys)\n",
    "5. Python and `pip`.\n",
    "\n",
    "## Installing dependencies\n",
    "\n",
    "The notebook requires the following packages:\n",
    "\n",
    "* `openai`\n",
    "* `pandas`\n",
    "* `wget`\n",
    "* `python-dotenv`\n",
    "* `opensearch-py`\n",
    "\n",
    "You can install the above packages with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    },
    "ExecuteTime": {
     "end_time": "2024-02-23T12:29:09.069320Z",
     "start_time": "2024-02-23T12:29:08.072657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (1.12.0)\r\n",
      "Requirement already satisfied: pandas in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (2.2.0)\r\n",
      "Requirement already satisfied: wget in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (3.2)\r\n",
      "Requirement already satisfied: python-dotenv in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: opensearch-py in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (2.4.2)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from openai) (4.3.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from openai) (0.27.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from openai) (2.6.1)\r\n",
      "Requirement already satisfied: sniffio in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from openai) (1.3.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from openai) (4.66.2)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from openai) (4.9.0)\r\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from pandas) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: urllib3>=1.26.18 in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from opensearch-py) (2.2.1)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.4.0 in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from opensearch-py) (2.31.0)\r\n",
      "Requirement already satisfied: six in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from opensearch-py) (1.16.0)\r\n",
      "Requirement already satisfied: certifi>=2022.12.07 in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from opensearch-py) (2024.2.2)\r\n",
      "Requirement already satisfied: idna>=2.8 in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jay.miller/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.4.0->opensearch-py) (3.3.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai pandas wget python-dotenv opensearch-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI key settings\n",
    "\n",
    "We'll use OpenAI to create embeddings starting from a set of documents, therefore an OpenAI API key is needed. You can get one from the [OpenAI API Key page](https://platform.openai.com/account/api-keys) after logging in.\n",
    "\n",
    "To avoid leaking the OpenAI key, you can store it as an environment variable named `OPENAI_API_KEY`. \n",
    "\n",
    "> For more information on how to perform the same task across other operative systems, refer to [Best Practices for API Key Safety](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety). \n",
    "\n",
    "To store safely the information, create a `.env` file in the same folder where the notebook is located and add the following line, replacing the `<INSERT_YOUR_API_KEY_HERE>` with your OpenAI API Key.\n",
    "\n",
    "```bash\n",
    "OPENAI_API_KEY=<INSERT_YOUR_API_KEY_HERE>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Aiven for OpenSearch\n",
    "\n",
    "Once the Aiven for OpenSearch service is in `RUNNING` state, we can retrieve the connection string from the Aiven for Opensearch service page, by copying the **Service URI** parameter. We can store it in the same `.env` file created above, after replacing the `https://USER:PASSWORD@HOST:PORT` string with the Service URI.\n",
    "\n",
    "```bash\n",
    "OPENSEARCH_URI=https://USER:PASSWORD@HOST:PORT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can now connect to Aiven for OpenSearch with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    },
    "ExecuteTime": {
     "end_time": "2024-02-23T12:29:09.123627Z",
     "start_time": "2024-02-23T12:29:09.064981Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from opensearchpy import OpenSearch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "connection_string = os.getenv(\"OPENSEARCH_URI\")\n",
    "\n",
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "client = OpenSearch(connection_string, use_ssl=True, timeout=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset\n",
    "To safe us from having to recalculate embeddings on a huge dataset, we are using a pre-calculated OpenAI embeddings dataset covering wikipedia articles. We can get the file and unzip it with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T12:29:12.430646Z",
     "start_time": "2024-02-23T12:29:09.123805Z"
    }
   },
   "outputs": [],
   "source": [
    "import wget\n",
    "import zipfile\n",
    "\n",
    "embeddings_url = 'https://cdn.openai.com/API/examples/data/vector_database_wikipedia_articles_embedded.zip'\n",
    "# wget.download(embeddings_url)\n",
    "\n",
    "with zipfile.ZipFile(\"vector_database_wikipedia_articles_embedded.zip\",\n",
    "\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the file in a dataframe and check the content with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T12:29:24.772422Z",
     "start_time": "2024-02-23T12:29:12.431568Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/qjmmz0rs7jx9bq6jrm_m30fh0000gq/T/ipykernel_52084/4275802152.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/plain": "   id                                       url   title  \\\n0   1   https://simple.wikipedia.org/wiki/April   April   \n1   2  https://simple.wikipedia.org/wiki/August  August   \n2   6     https://simple.wikipedia.org/wiki/Art     Art   \n3   8       https://simple.wikipedia.org/wiki/A       A   \n4   9     https://simple.wikipedia.org/wiki/Air     Air   \n\n                                                text  \\\n0  April is the fourth month of the year in the J...   \n1  August (Aug.) is the eighth month of the year ...   \n2  Art is a creative activity that expresses imag...   \n3  A or a is the first letter of the English alph...   \n4  Air refers to the Earth's atmosphere. Air is a...   \n\n                                        title_vector  \\\n0  [0.001009464613161981, -0.020700545981526375, ...   \n1  [0.0009286514250561595, 0.000820168002974242, ...   \n2  [0.003393713850528002, 0.0061537534929811954, ...   \n3  [0.0153952119871974, -0.013759135268628597, 0....   \n4  [0.02224554680287838, -0.02044147066771984, -0...   \n\n                                      content_vector  vector_id  \n0  [-0.011253940872848034, -0.013491976074874401,...          0  \n1  [0.0003609954728744924, 0.007262262050062418, ...          1  \n2  [-0.004959689453244209, 0.015772193670272827, ...          2  \n3  [0.024894846603274345, -0.022186409682035446, ...          3  \n4  [0.021524671465158463, 0.018522677943110466, -...          4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>url</th>\n      <th>title</th>\n      <th>text</th>\n      <th>title_vector</th>\n      <th>content_vector</th>\n      <th>vector_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>https://simple.wikipedia.org/wiki/April</td>\n      <td>April</td>\n      <td>April is the fourth month of the year in the J...</td>\n      <td>[0.001009464613161981, -0.020700545981526375, ...</td>\n      <td>[-0.011253940872848034, -0.013491976074874401,...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>https://simple.wikipedia.org/wiki/August</td>\n      <td>August</td>\n      <td>August (Aug.) is the eighth month of the year ...</td>\n      <td>[0.0009286514250561595, 0.000820168002974242, ...</td>\n      <td>[0.0003609954728744924, 0.007262262050062418, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>https://simple.wikipedia.org/wiki/Art</td>\n      <td>Art</td>\n      <td>Art is a creative activity that expresses imag...</td>\n      <td>[0.003393713850528002, 0.0061537534929811954, ...</td>\n      <td>[-0.004959689453244209, 0.015772193670272827, ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8</td>\n      <td>https://simple.wikipedia.org/wiki/A</td>\n      <td>A</td>\n      <td>A or a is the first letter of the English alph...</td>\n      <td>[0.0153952119871974, -0.013759135268628597, 0....</td>\n      <td>[0.024894846603274345, -0.022186409682035446, ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>https://simple.wikipedia.org/wiki/Air</td>\n      <td>Air</td>\n      <td>Air refers to the Earth's atmosphere. Air is a...</td>\n      <td>[0.02224554680287838, -0.02044147066771984, -0...</td>\n      <td>[0.021524671465158463, 0.018522677943110466, -...</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "wikipedia_dataframe = pd.read_csv(\"data/vector_database_wikipedia_articles_embedded.csv\")\n",
    "\n",
    "wikipedia_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file contains:\n",
    "* `id` a unique Wikipedia article identifier\n",
    "* `url` the Wikipedia article URL\n",
    "* `title` the title of the Wikipedia page\n",
    "* `text` the text of the article\n",
    "* `title_vector` and `content_vector` the embedding calculated on the title and content of the wikipedia article respectively\n",
    "* `vector_id` the id of the vector\n",
    "\n",
    "We can create an OpenSearch mapping optimized for the storage of these information with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T12:29:24.773861Z",
     "start_time": "2024-02-23T12:29:24.771318Z"
    }
   },
   "outputs": [],
   "source": [
    "index_settings ={\n",
    "    \"index\": {\n",
    "      \"knn\": True,\n",
    "      \"knn.algo_param.ef_search\": 100\n",
    "    }\n",
    "  }\n",
    "\n",
    "index_mapping= {\n",
    "    \"properties\": {\n",
    "      \"title_vector\": {\n",
    "          \"type\": \"knn_vector\",\n",
    "          \"dimension\": 1536,\n",
    "          \"method\": {\n",
    "            \"name\": \"hnsw\",\n",
    "            \"space_type\": \"l2\",\n",
    "            \"engine\": \"faiss\"\n",
    "        }\n",
    "      },\n",
    "      \"content_vector\": {\n",
    "          \"type\": \"knn_vector\",\n",
    "          \"dimension\": 1536,\n",
    "          \"method\": {\n",
    "            \"name\": \"hnsw\",\n",
    "            \"space_type\": \"l2\",\n",
    "            \"engine\": \"faiss\"\n",
    "        },\n",
    "      },\n",
    "      \"text\": {\"type\": \"text\"},\n",
    "      \"title\": {\"type\": \"text\"},\n",
    "      \"url\": { \"type\": \"keyword\"},\n",
    "      \"vector_id\": {\"type\": \"long\"}\n",
    "      \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And create an index in Aiven for OpenSearch with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T12:29:25.577742Z",
     "start_time": "2024-02-23T12:29:24.773794Z"
    }
   },
   "outputs": [
    {
     "ename": "RequestError",
     "evalue": "RequestError(400, 'resource_already_exists_exception', 'index [openai_wikipedia_index/Tey9zgGiRLedfWnhwfw3gg] already exists')",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRequestError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m index_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mopenai_wikipedia_index\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msettings\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex_settings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmappings\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43mindex_mapping\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages/opensearchpy/client/utils.py:181\u001B[0m, in \u001B[0;36mquery_params.<locals>._wrapper.<locals>._wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    178\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m v \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    179\u001B[0m             params[p] \u001B[38;5;241m=\u001B[39m _escape(v)\n\u001B[0;32m--> 181\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages/opensearchpy/client/indices.py:166\u001B[0m, in \u001B[0;36mIndicesClient.create\u001B[0;34m(self, index, body, params, headers)\u001B[0m\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m SKIP_IN_PATH:\n\u001B[1;32m    164\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEmpty value passed for a required argument \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 166\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransport\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mperform_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPUT\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_make_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages/opensearchpy/transport.py:448\u001B[0m, in \u001B[0;36mTransport.perform_request\u001B[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001B[0m\n\u001B[1;32m    446\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    447\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 448\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;66;03m# connection didn't fail, confirm its live status\u001B[39;00m\n\u001B[1;32m    452\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconnection_pool\u001B[38;5;241m.\u001B[39mmark_live(connection)\n",
      "File \u001B[0;32m~/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages/opensearchpy/transport.py:409\u001B[0m, in \u001B[0;36mTransport.perform_request\u001B[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001B[0m\n\u001B[1;32m    406\u001B[0m connection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_connection()\n\u001B[1;32m    408\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 409\u001B[0m     status, headers_response, data \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mperform_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    410\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    412\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    413\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    414\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    415\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    416\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    419\u001B[0m     \u001B[38;5;66;03m# Lowercase all the header names for consistency in accessing them.\u001B[39;00m\n\u001B[1;32m    420\u001B[0m     headers_response \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    421\u001B[0m         header\u001B[38;5;241m.\u001B[39mlower(): value \u001B[38;5;28;01mfor\u001B[39;00m header, value \u001B[38;5;129;01min\u001B[39;00m headers_response\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m    422\u001B[0m     }\n",
      "File \u001B[0;32m~/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages/opensearchpy/connection/http_urllib3.py:290\u001B[0m, in \u001B[0;36mUrllib3HttpConnection.perform_request\u001B[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001B[0m\n\u001B[1;32m    286\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;241m200\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m300\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ignore:\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog_request_fail(\n\u001B[1;32m    288\u001B[0m         method, full_url, url, orig_body, duration, response\u001B[38;5;241m.\u001B[39mstatus, raw_data\n\u001B[1;32m    289\u001B[0m     )\n\u001B[0;32m--> 290\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_error\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    291\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstatus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    292\u001B[0m \u001B[43m        \u001B[49m\u001B[43mraw_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    293\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_response_headers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent-type\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    294\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog_request_success(\n\u001B[1;32m    297\u001B[0m     method, full_url, url, orig_body, response\u001B[38;5;241m.\u001B[39mstatus, raw_data, duration\n\u001B[1;32m    298\u001B[0m )\n\u001B[1;32m    300\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus, response\u001B[38;5;241m.\u001B[39mheaders, raw_data\n",
      "File \u001B[0;32m~/PycharmProjects/aiven-openai-cookbook/.venv/lib/python3.12/site-packages/opensearchpy/connection/base.py:316\u001B[0m, in \u001B[0;36mConnection._raise_error\u001B[0;34m(self, status_code, raw_data, content_type)\u001B[0m\n\u001B[1;32m    313\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    314\u001B[0m     logger\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUndecodable raw error response from server: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, err)\n\u001B[0;32m--> 316\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m HTTP_EXCEPTIONS\u001B[38;5;241m.\u001B[39mget(status_code, TransportError)(\n\u001B[1;32m    317\u001B[0m     status_code, error_message, additional_info\n\u001B[1;32m    318\u001B[0m )\n",
      "\u001B[0;31mRequestError\u001B[0m: RequestError(400, 'resource_already_exists_exception', 'index [openai_wikipedia_index/Tey9zgGiRLedfWnhwfw3gg] already exists')"
     ]
    }
   ],
   "source": [
    "index_name = \"openai_wikipedia_index\"\n",
    "client.indices.create(index=index_name, body={\"settings\": index_settings, \"mappings\":index_mapping})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index data into OpenSearch\n",
    "\n",
    "Now it's time to parse the the pandas dataframe and index the data into OpenSearch using Bulk APIs. The following function indexes a set of rows in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T12:29:25.580815Z",
     "start_time": "2024-02-23T12:29:25.578399Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataframe_to_bulk_actions(df):\n",
    "    for index, row in df.iterrows():\n",
    "        yield {\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": row['id'],\n",
    "            \"_source\": {\n",
    "                'url' : row[\"url\"],\n",
    "                'title' : row[\"title\"],\n",
    "                'text' : row[\"text\"],\n",
    "                'title_vector' : json.loads(row[\"title_vector\"]),\n",
    "                'content_vector' : json.loads(row[\"content_vector\"]),\n",
    "                'vector_id' : row[\"vector_id\"]\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want to index all the dataset at once, since it's way too large, so we'll load it in batches of `200` rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-23T12:29:25.579991Z"
    }
   },
   "outputs": [],
   "source": [
    "from opensearchpy import helpers\n",
    "import json\n",
    "\n",
    "start = 0\n",
    "end = len(wikipedia_dataframe)\n",
    "batch_size = 200\n",
    "for batch_start in range(start, end, batch_size):\n",
    "    batch_end = min(batch_start + batch_size, end)\n",
    "    batch_dataframe = wikipedia_dataframe.iloc[batch_start:batch_end]\n",
    "    actions = dataframe_to_bulk_actions(batch_dataframe)\n",
    "    helpers.bulk(client, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the documents are indexed, let's try a query to retrieve the documents containing `Pizza`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-23T12:29:25.581421Z"
    }
   },
   "outputs": [],
   "source": [
    "res = client.search(index=index_name, body={\n",
    "    \"_source\": {\n",
    "        \"excludes\": [\"title_vector\", \"content_vector\"]\n",
    "    },\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"text\": {\n",
    "                \"query\": \"Pizza\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "print(res[\"hits\"][\"hits\"][0][\"_source\"][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode questions with OpenAI\n",
    "\n",
    "To perform a semantic search, we need to calculate questions encodings with the same embedding model used to encode the documents at index time. In this example, we need to use the `text-embedding-3-small` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T12:30:24.187277Z",
     "start_time": "2024-02-23T12:30:23.540454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Define model\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "# Define the Client\n",
    "openaiclient = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "# Define question\n",
    "question = 'is Pineapple a good ingredient for Pizza?'\n",
    "\n",
    "# Create embedding\n",
    "question_embedding = openaiclient.embeddings.create(input=question, model=EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run semantic search queries with OpenSearch\n",
    "\n",
    "With the above embedding calculated, we can now run semantic searches against the OpenSearch index. We're using `knn` as query type and scan the content of the `content_vector` field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T12:30:43.227163Z",
     "start_time": "2024-02-23T12:30:40.382495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id:66079\n",
      "Score: 0.71338785\n",
      "Title: Pizza Pizza\n",
      "Text: Pizza Pizza Limited (PPL), doing business as Pizza Pizza (), is a franchised Canadian pizza fast foo\n",
      "Id:15719\n",
      "Score: 0.7115042\n",
      "Title: Pineapple\n",
      "Text: The pineapple is a fruit. It is native to South America, Central America and the Caribbean. The word\n",
      "Id:13967\n",
      "Score: 0.7106797\n",
      "Title: Pizza\n",
      "Text: Pizza is an Italian food that was created in Italy (The Naples area). It is made with different topp\n",
      "Id:13968\n",
      "Score: 0.69487476\n",
      "Title: Pepperoni\n",
      "Text: Pepperoni is a meat food that is sometimes sliced thin and put on pizza. It is a kind of salami, whi\n",
      "Id:40989\n",
      "Score: 0.6696015\n",
      "Title: Coprophagia\n",
      "Text: Coprophagia is the eating of faeces. Many animals eat faeces, either their own or that of other anim\n",
      "Id:90918\n",
      "Score: 0.66611433\n",
      "Title: Pizza Hut\n",
      "Text: Pizza Hut is an American pizza restaurant, or pizza parlor. Pizza Hut also serves salads, pastas and\n",
      "Id:45877\n",
      "Score: 0.66580874\n",
      "Title: Papaya\n",
      "Text: Papaya is a tall herbaceous plant in the genus Carica; its edible fruit is also called papaya. It is\n",
      "Id:41467\n",
      "Score: 0.6646078\n",
      "Title: Te Puke\n",
      "Text: Te Puke is a small town in the Bay of Plenty in New Zealand. 6670 people live there. It is famous fo\n",
      "Id:61037\n",
      "Score: 0.6569093\n",
      "Title: Dough\n",
      "Text: Dough is a thick, malleable and sometimes elastic paste made out of flour by mixing it with a small \n",
      "Id:60337\n",
      "Score: 0.6567663\n",
      "Title: Pastry\n",
      "Text: Pastry is the dough from which some baked products are made. Pastry dough is rolled out thinly and u\n",
      "Id:76670\n",
      "Score: 0.6560743\n",
      "Title: Lycopene\n",
      "Text: Lycopene is the pigment of tomato. Its chemical formula is (6E,8E,10E,12E,14E,16E,18E,20E,22E,24E,26\n",
      "Id:58500\n",
      "Score: 0.65550375\n",
      "Title: Feijoa\n",
      "Text: The feijoa is the fruit of Acca sellowiana, an evergreen shrub or small tree, 1â€“7 m in height. It co\n",
      "Id:79026\n",
      "Score: 0.65358526\n",
      "Title: Pectin\n",
      "Text: Pectin is a food supplement. It is a source of dietary fiber. It is used to make jellies and jams. U\n",
      "Id:66912\n",
      "Score: 0.6429344\n",
      "Title: Ripening\n",
      "Text: Ripening is when fruit becomes easier to eat. Some fruits, like the tomato or the mango, will contin\n",
      "Id:67492\n",
      "Score: 0.6426564\n",
      "Title: Guacamole\n",
      "Text: Guacamole (called Guacamol in Central America and Cuba) is a Mexican dip made of avocados, salt and \n"
     ]
    }
   ],
   "source": [
    "response = client.search(\n",
    "  index = index_name,\n",
    "  body = {\n",
    "      \"size\": 15,\n",
    "      \"query\" : {\n",
    "        \"knn\" : {\n",
    "          \"content_vector\":{\n",
    "          \"vector\":  question_embedding.data[0].embedding,\n",
    "          \"k\": 3\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    ")\n",
    "\n",
    "for result in response[\"hits\"][\"hits\"]:\n",
    "  print(\"Id:\" + str(result['_id']))\n",
    "  print(\"Score: \" + str(result[\"_score\"]))\n",
    "  print(\"Title: \" + str(result[\"_source\"][\"title\"]))\n",
    "  print(\"Text: \" + result[\"_source\"][\"text\"][0:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use OpenAI Chat Completions API to generate a reply\n",
    "\n",
    "The step above retrieves the content semantically similar to the question, now let's use OpenAI chat `completions` to generate a reply based on the information retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T12:31:19.459814Z",
     "start_time": "2024-02-23T12:31:16.397246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Pineapple is a common ingredient found in pizzas, including those offered by Pizza Pizza Limited. It is listed alongside other toppings like pepperoni and mushrooms. Pizza Pizza, a Canadian franchise, has been serving customers for over 30 years, expanding its reach to over 500 locations in Ontario and beyond.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the text of the first result in the above dataset\n",
    "top_hit_summary = response['hits']['hits'][0]['_source']['text']\n",
    "\n",
    "# Craft a reply\n",
    "response = openaiclient.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Answer the following question:\" \n",
    "            + question \n",
    "            + \"by using the following text:\" \n",
    "            + top_hit_summary\n",
    "        }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "choices = response.choices\n",
    "\n",
    "for choice in choices:\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    print(choice.message.content)\n",
    "    print(\"------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "OpenSearch is a powerful tool providing both text and vector search capabilities. Used alongside OpenAI APIs allows you to craft personalized AI applications able to augment the context based on semantic search.\n",
    "\n",
    "You can try Aiven for OpenSearch, or any of the other Open Source tools, in the Aiven platform free trial by [signing up](https://go.aiven.io/openai-opensearch-signup)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
